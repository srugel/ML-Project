Activity Recognition of Barbell Lift Exercises
========================================================
*S.Rugel*

## Introduction
The goal of this analysis is to build a model predicting the correctness of barbell lift movements on base of a collection of personal movement data. Data on movement have been collected by a couple of persons while repeatedly exercysing barbell lifts. The data have been generated by accelerometers and other measurement devices placed at belt, forearm, arm  and dumbell. Exercises have been performed correctly and in four different uncorrect ways (see (http://groupware.les.inf.puc-rio.br/har) for further information), which have to be predicted by the model.


## Input data and feature selection

We download the "training"- and "test"" data, available under (https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)[pml-training.csv] and (https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)[pml-testing.csv] into WD.  
We read the training- and test dataset:
```{r}
x<-read.csv("pml-training.csv")
z<-read.csv("pml-testing.csv")
```

The test data contain 160 columns and 20 rows, however there is a large number of columns which are entirely NA.

```{r}
isna<-apply(z,2,function(x) {sum(is.na(x))}) == 20
sum(isna)
```
  
As we finally have to predict the outcome of the test data with our model, we can only use the testfile covariates with non-NA content as model parameters, i.e. we have to subset the training data accordingly.  
We also remove the first 7 columns from the "training" data as those only specify the indivual observations and are uncorrelated with the model classifier "classe". 
We also keep the model classifier. The last column of the test data, "ploblem_id", does not appear in the training data and is therefor not considered.   

```{r}
library(caret)
validCols<-colnames(z)[!isna]
x2 <- subset(x,select=c(validCols[8:59],"classe"))
```

## Data Pre-Processing

We create training- and test sets (further referenced as such, don't mix with "training"- and "test" input data):

```{r}
set.seed(12345)
inTrain<-createDataPartition(y=x2$classe,p=0.7,list=FALSE)
training<-x2[inTrain,]
testing<-x2[-inTrain,]
```

In order to reduce the number of parameters, the training set is pre-processed by PCA, preserving 95% of the original variance, which reduces the dimension in parameter space to 25 (column 53 contains the classifier): 

```{r}
preProc <- preProcess(training[,-53],method="pca",thresh=0.95)
preProc
```

We then perform rotation of the parameters in the training- and test set:

```{r}
trainPC<-predict(preProc,training[,-53])
testPC<-predict(preProc,testing[,-53])
```

## Model selection and model evaluation
We select "random forest" for our model as we need a high prediction accuracy.

```{r}
modelFit<-train(training$classe ~ .,method="rf",data=trainPC)
modelFit
```

Cross validation against the test set results in an accuracy of  c.a. 2% within a confidence interval of 0.05%:

```{r}
predTest<-predict(modelFit,testPC)
confusionMatrix(testing$classe,predTest)
```

Finally, the model defined in this paper has to predict the outcome of 20 test samples.
With a prediction accuracy out of sample of 98%, we expect 94% of test results being 0 or 1 error, 67% probability for zero errors alone. 
This seems to be acceptable, so we take "modelFit" as our model for further predictions.

## Prediction for "pml-testing.csv"

We predict the classes for "pml-testing.csv" as follows:

```{r}
z2 <- subset(z,select=c(validCols[8:59]))
answerPC<-predict(preProc,z2)
answer<-predict(modelFit,answerPC)
answer
```
